{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "layers = tensorflow.keras.layers\n",
    "BatchNormalization = tensorflow.keras.layers.BatchNormalization\n",
    "Conv2D = tensorflow.keras.layers.Conv2D\n",
    "Flatten = tensorflow.keras.layers.Flatten\n",
    "TensorBoard = tensorflow.keras.callbacks.TensorBoard\n",
    "ModelCheckpoint = tensorflow.keras.callbacks.ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# load an image from file\n",
    "import sys\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from numpy import expand_dims\n",
    "\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from numpy import expand_dims\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "from PIL import Image\n",
    "#from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    #rescale=1/255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=1,\n",
    "    fill_mode='wrap', \n",
    "    cval=190,\n",
    "    height_shift_range=1,\n",
    "    brightness_range=(.7,1.3),\n",
    "    shear_range=0.8,\n",
    "    zoom_range=[.6,1.8],\n",
    "    #channel_shift_range=.7,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    #rescale=1/255,\n",
    "    #rotation_range=30,\n",
    "    width_shift_range=1,\n",
    "    height_shift_range=1,\n",
    "    brightness_range=(.8,1.1),\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[.8,1.2],\n",
    "    #channel_shift_range=.7,\n",
    "    fill_mode=\"nearest\",\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    preprocessing_function=preprocess_input)\n",
    "    #rescale=1/255,\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define a new model with random weights and 10 classes\n",
    "new_input = Input(shape=(224, 224, 3))\n",
    "model = VGG16( weights='imagenet',input_shape=new_input, classes=44,include_top=False)\n",
    "keras.layers.Dense(64, activation='relu'),\n",
    "keras.layers.Dense(44, activation='softmax'),\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "es=EarlyStopping(patience=5, monitor='loss',verbose=1)\n",
    "\n",
    "model.fit(X, y, epochs=1000,callbacks=[es],validation_split=.1)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X, y)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "#model.fit(X,y,epochs=10,validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data augmentation\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "# setup generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory='/Users/denisdunn/Desktop/'+'full_aerin',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        color_mode='rgb',\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# train model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator, # optional - if used needs to be defined\n",
    "    validation_steps=nb_validation_samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(r\"C:\\Users\\dedunn\\Downloads\\weights-improvement-92-0.70.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "model=VGG16(include_top=False, weights='imagenet',input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import resnet50\n",
    "resnet50 = resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "#model.load_weights('resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VGG16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#25088\n",
    "model.add(VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.build(input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in new_model.layers[:1]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.add(tensorflow.keras.layers.Dense(43, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.add(model)\n",
    "new_model.add(tensorflow.keras.layers.Flatten()),\n",
    "new_model.add(tensorflow.keras.layers.Dense(4086, activation='elu')),\n",
    "new_model.add(tensorflow.keras.layers.Dense(528, activation='elu')),\n",
    "new_model.add(tensorflow.keras.layers.Dense(128, activation='elu')),     \n",
    "new_model.add(tensorflow.keras.layers.Dense(43, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(44, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#25088\n",
    "#build(VGG16)\n",
    "#model.add(VGG16)\n",
    "#model = model_2.Sequential()\n",
    "#model = keras.Sequential()\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False   # go through until last layer\n",
    "    #layer.name = layer.name + str(\"_2\")\n",
    "    #model.add(layer)\n",
    "#model.add(keras.layers.Flatten()),\n",
    "#model.add(keras.layers.Dense(4086, activation='elu')),\n",
    "#model.add(layers.Dense(528, activation='elu')),\n",
    "#model.add(layers.Dense(128, activation='elu')),     \n",
    "#model.add(layers.Dense(44, activation='softmax')) \n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "# Add new layers\n",
    "\n",
    "#model.add(layers.Flatten(input_shape=(20,20,1)))\n",
    "\n",
    "#model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "#model.add(layers.Dropout(0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(r\"C:\\Users\\dedunn\\Desktop\\weights-improvement-123-0.99.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins'):\n",
    "    print(entry_point.dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(r\"C:\\Users\\dedunn\\Desktop\\weights-improvement-27-0.85.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The Keras Tuner Authors\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Keras Tuner hello world with MNIST.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from kerastuner import RandomSearch\n",
    "\n",
    "TRIALS = 3  # number of models to train\n",
    "EPOCHS = 2  # number of epoch per model\n",
    "\n",
    "# Get the MNIST dataset.\n",
    "    #(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "    #x_train = np.expand_dims(x_train.astype('float32') / 255, -1)\n",
    "    #x_val = np.expand_dims(x_val.astype('float32') / 255, -1)\n",
    "    #y_train = to_categorical(y_train, 10)\n",
    "    #y_val = to_categorical(y_val, 10)\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"Function that build a TF model based on hyperparameters values.\n",
    "\n",
    "    Args:\n",
    "        hp (HyperParameter): hyperparameters values\n",
    "\n",
    "    Returns:\n",
    "        Model: Compiled model\n",
    "    \"\"\"\n",
    "\n",
    "    num_layers = hp.Int('num_layers', 2, 8, default=6)\n",
    "    lr = hp.Choice('learning_rate', [1e-3, 5e-4])\n",
    "\n",
    "    inputs = layers.Input(shape=(28, 28, 1))\n",
    "    x = inputs\n",
    "\n",
    "    for idx in range(num_layers):\n",
    "        idx = str(idx)\n",
    "\n",
    "        filters = hp.Int('filters_' + idx, 32, 256, step=32, default=64)\n",
    "        x = layers.Conv2D(filters=filters, kernel_size=3, padding='same',\n",
    "                          activation='relu')(x)\n",
    "\n",
    "        # add a pooling layers if needed\n",
    "        if x.shape[1] >= 8:\n",
    "            pool_type = hp.Choice('pool_' + idx, values=['max', 'avg'])\n",
    "            if pool_type == 'max':\n",
    "                x = layers.MaxPooling2D(2)(x)\n",
    "            elif pool_type == 'avg':\n",
    "                x = layers.AveragePooling2D(2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    # Build model\n",
    "    model = tensorflow.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='SGD',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize the tuner by passing the `build_model` function\n",
    "# and specifying key search constraints: maximize val_acc (objective),\n",
    "# and the number of trials to do. More efficient tuners like UltraBand() can\n",
    "# be used.\n",
    "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=TRIALS,\n",
    "                     project_name='hello_world_tutorial_results')\n",
    "\n",
    "# Display search space overview\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "# Perform the model search. The search function has the same signature\n",
    "# as `model.fit()`.\n",
    "#tuner.search(x_train, y_train, batch_size=128, epochs=2,\n",
    "             #validation_data=(x_val, y_val))\n",
    "\n",
    "# Display the best models, their hyperparameters, and the resulting metrics.\n",
    "#tuner.results_summary()\n",
    "\n",
    "# Retrieve the best model and display its architecture\n",
    "#best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = l1(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(tensorflow.keras.layers.Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),strides=(1,1),activation=\"relu\",padding=\"valid\")),\n",
    "model.add(tensorflow.keras.layers.BatchNormalization(axis=-1)),\n",
    "#model.add(tensorflow.keras.layers.Activation('relu')),\n",
    "model.add(tensorflow.keras.layers.Dropout(0.5)),\n",
    "#model.add(tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")),\n",
    "#model.add(tensorflow.keras.layers.BatchNormalization(axis=-1)),\n",
    "#model.add(tensorflow.keras.layers.Dropout(0.5)),\n",
    "model.add(tensorflow.keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(1,1), padding='valid')),\n",
    "#model.add(tensorflow.keras.layers.Dropout(0.5)),\n",
    "#model.add(tensorflow.keras.layers.Conv2D(filters=128, kernel_size=(3,3),strides=(1,1),activation=\"relu\", padding=\"valid\")),\n",
    "#model.add(tensorflow.keras.layers.Dropout(0.5)),\n",
    "model.add(tensorflow.keras.layers.BatchNormalization(axis=-1)),\n",
    "#model.add(tensorflow.keras.layers.Activation('relu')),\n",
    "model.add(tensorflow.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)),\n",
    "model.add(tensorflow.keras.layers.Flatten()),\n",
    "#model.add(tensorflow.keras.layers.Dense(86, activation='relu')),\n",
    "#model.add(tensorflow.keras.layers.Dense(64, activation='relu'))\n",
    "#model.add(tensorflow.keras.layers.Dropout(0.5))\n",
    "model.add(tensorflow.keras.layers.Dense(2, activation='softmax')),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tensorflow.keras.callbacks.TensorBoard(log_dir=\"/Users/denisdunn/Desktop/logs/{}\".format(time()),histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:ModelCheckpoint mode least is unknown, fallback to auto mode.\n",
      "Found 2 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2 steps\n",
      "Epoch 1/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3097 - accuracy: 1.0000\n",
      "Epoch 00001: loss improved from inf to 0.15556, saving model to weights-improvement-01-1.00.hdf5\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.1556 - accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 31.8548 - accuracy: 0.0000e+00\n",
      "Epoch 00002: loss did not improve from 0.15556\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 39.0134 - accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00003: loss improved from 0.15556 to 0.00000, saving model to weights-improvement-03-1.00.hdf5\n",
      "2/2 [==============================] - 1s 337ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 15.0416 - accuracy: 0.0000e+00\n",
      "Epoch 00004: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 7.5208 - accuracy: 0.5000\n",
      "Epoch 5/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00005: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 336ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00006: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 345ms/step - loss: 27.2555 - accuracy: 0.5000\n",
      "Epoch 7/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 00007: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.1791e-06 - accuracy: 1.0000\n",
      "Epoch 00008: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 4.5895e-06 - accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 103.4220 - accuracy: 0.0000e+00\n",
      "Epoch 00009: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 336ms/step - loss: 109.2170 - accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00010: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00011: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00012: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00013: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00014: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 39.2918 - accuracy: 0.5000\n",
      "Epoch 15/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00015: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 342ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 45.4682 - accuracy: 0.0000e+00\n",
      "Epoch 00016: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 325ms/step - loss: 22.7341 - accuracy: 0.5000\n",
      "Epoch 17/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00017: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 331ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00018: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 325ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00019: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00020: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00021: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00022: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00023: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 4.1128e-04 - accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00024: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00025: loss did not improve from 0.00000\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-e93221979f19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m model.fit_generator(train_generator,\n\u001b[1;32m     20\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#validation_data=valid_generator,validation_steps=len(valid_generator),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     epochs=1000,callbacks=[checkpoint]) \n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run in separate terminal before training\n",
    "#tensorboard --logdir=/Users/denisdunn/Desktop/logs/\n",
    "sgd= optimizers.SGD(lr=.001,clipnorm=1.0)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "filepath=\"weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='least')\n",
    "#callbacks_list = [checkpoint]\n",
    "#es=EarlyStopping(patience=15, monitor='loss',verbose=1)\n",
    "#datagen.fit(X)\n",
    "train_generator =datagen.flow_from_directory(\n",
    "        directory='/Users/denisdunn/Desktop/estee_video_demo',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch=len(train_generator),#validation_data=valid_generator,validation_steps=len(valid_generator),\n",
    "    epochs=1000,callbacks=[checkpoint]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator =valid_datagen.flow_from_directory(\n",
    "        directory=\"/Users/denisdunn/Desktop/estee_video_demo\",\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('video_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_generator,\n",
    "steps=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    #keras.layers.Conv2D(input_shape=(50,50,1),filters=64,kernel_size=(1,1), activation='relu',strides=(1,1),padding='valid'),\n",
    "    #keras.layers.BatchNormalization(axis=-1,momentum=.99,epsilon=.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zero',moving_variance_initializer='ones'),\n",
    "    #keras.layers.Conv2D(filters=256,kernel_size=(5,5), strides=(3,3),padding='valid', activation='elu'),\n",
    "    #keras.layers.BatchNormalization(axis=-1),#momentum=.99,epsilon=.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zero',moving_variance_initializer='ones'),\n",
    "    #keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='valid'),\n",
    "    keras.layers.Flatten(input_shape=(20,20,1)),\n",
    "    #keras.layers.Dense(4096),\n",
    "    #keras.layers.ELU(alpha=1.0),\n",
    "    keras.layers.Dense(528, activation='elu'),\n",
    "    #keras.layers.BatchNormalization(axis=-1),#momentum=.99,epsilon=.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zero',moving_variance_initializer='ones'),\n",
    "    keras.layers.Dense(528, activation='elu'),\n",
    "    #keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(128, activation='elu'),\n",
    "    #keras.layers.Dropout(.5),\n",
    "    keras.layers.Dense(64, activation='elu'),\n",
    "    keras.layers.Dense(44, activation='softmax'),\n",
    "])\n",
    "sgd= optimizers.SGD(lr=.1,decay=1e-1, momentum=.9,nesterov=True)\n",
    "model.compile(optimizer=\"SGD\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "filepath=\"weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "#es=EarlyStopping(patience=15, monitor='loss',verbose=1)\n",
    "#datagen.fit(X)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        directory='/Users/denisdunn/Desktop/'+'full_aerin',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=1000,callbacks=[checkpoint]) \n",
    "#model.fit_generator(datagen.flow(X,y,batch_size=4),\n",
    "     #steps_per_epoch=(len(X)//4),callbacks=[checkpoint],\n",
    "    #epochs=30000)\n",
    "#model.fit(X, y, epochs=500, batch_size=32,callbacks=[es],validation_split=.1)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X, y)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data augmentation\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "# setup generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# train model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator, # optional - if used needs to be defined\n",
    "    validation_steps=nb_validation_samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('128_filters_100_color_2conv_max_batch2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES=os.listdir('/Users/denisdunn/Desktop/estee_video_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AERIN_TLJ_DIGITAL_1.jpg', 'FL17_AERIN_TLJ_TLS_HERO.jpg']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"/Users/denisdunn/estee_lauder/weights-improvement-03-1.00.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"/Users/denisdunn/Desktop/Screen Shot 2020-04-17 at 4.29.14 PM.png\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AERIN_TLJ_DIGITAL_1.jpg\n"
     ]
    }
   ],
   "source": [
    "img1=load_img(img_path, target_size=(224, 224))\n",
    "y=img_to_array(img1)\n",
    "y=np.expand_dims(y, axis=0)\n",
    "y = preprocess_input(y)\n",
    "result=model.predict_classes(y)\n",
    "print(CATEGORIES[int(result)])\n",
    "#features = model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(y)[:,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-4267b5628613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculate roc curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# calculate the g-mean for each threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# locate the index of the largest g-mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testy' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(testy, yhat)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "largest_indices(multi,3)[-1][0]\n",
    "print(CATEGORIES[int(largest_indices(multi,3)[-1][0])])\n",
    "print(CATEGORIES[int(largest_indices(multi,3)[-1][1])])\n",
    "#print(CATEGORIES[int(largest_indices(multi,3)[-3][2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=model.predict_classes(y)\n",
    "print(CATEGORIES[int(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(np.argmax(features,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(ans,axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls=features[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(test):\n",
    "    #array_test=img_to_array(test)\n",
    "    #img_array=cv2.imread(test)\n",
    "    array_resize=cv2.resize(test,(IMG_SIZE,IMG_SIZE))\n",
    "    test_image = array_resize[...,::-1]\n",
    "    return (np.array(test_image).reshape(1,IMG_SIZE,IMG_SIZE,3))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = cv2.imread('/Users/denisdunn/Desktop/F19_AERIN_LIM_DIGITAL_1_R300.tif')#,cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "test_image = new_array[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denis=cv2.imread('/Users/denisdunn/Desktop/191001_LSF_SHOT24_6612_2480DI_i_ADOBERGB.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "#cv2.IMREAD_GRAYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                test_image = new_array[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=image_processing(denis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic='/Users/denisdunn/Desktop/HOL19_AERIN_ MODEL_F72.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pic_test(pic):\n",
    "    denis=cv2.imread(pic)#,cv2.IMREAD_GRAYSCALE)\n",
    "    answer=image_processing(denis)\n",
    "    result=model.predict_classes(answer)\n",
    "    direct='/Users/denisdunn/Desktop/full_aerin/{}/{}'.format(CATEGORIES[int(result)],CATEGORIES[int(result)])\n",
    "    return load_img(direct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct='/Users/denisdunn/Desktop/full_aerin/{}/{}'.format(CATEGORIES[int(result)],CATEGORIES[int(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_test('/Users/denisdunn/Desktop/_0_117.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('feb_5_size_25_batch5_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/denisdunn/Desktop/DATADIR/X',X)\n",
    "np.save('/Users/denisdunn/Desktop/DATADIR/y',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Conv2D(input_shape=(32,32,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Flatten(),\n",
    "keras.layers.Dense(units=4096,activation=\"relu\"),\n",
    "keras.layers.Dense(units=4096,activation=\"relu\"),\n",
    "keras.layers.Dense(units=44, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "es=EarlyStopping(patience=20, monitor='acc',verbose=1)\n",
    "model.fit(X, y, epochs=1000, batch_size=10,callbacks=[es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X, y)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "from six.moves import range\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2,time\n",
    "import numpy as np\n",
    "print(cv2.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('file:///Users/denisdunn/opt/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.imread('/Users/denisdunn/Desktop/Ivb19_0881-319x319.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=face_cascade.detectMultiScale(gray,scaleFactor=1.05,minNeighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,w,h, in faces:\n",
    "    img = cv2.rectangle(gray, (x,y), (x+w,y+h),(0,255,0),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('gray',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "\n",
    "#cvim2disp = cv2.imread('/Users/denisdunn/Desktop/Ivb19_0881-319x319.png')\n",
    "cv2.imshow('img', img)\n",
    "while(True):\n",
    "    k = cv2.waitKey(33)\n",
    "    if k == -1:  # if no key was pressed, -1 is returned\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyWindow('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=cv2.VideoCapture(0)\n",
    "check,frame=video.read()\n",
    "time.sleep(3) \n",
    "cv2.imshow('Capture',frame)\n",
    "cv2.waitKey(0)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyWindow('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/denisdunn/Desktop/shirt_test.png'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "while(True):\n",
    "    k = cv2.waitKey(33)\n",
    "    if k == -1:  # if no key was pressed, -1 is returned\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyWindow('img')\n",
    "#if cv2.waitKey(0) & 0xff == 27:\n",
    "    #cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/denisdunn/Desktop/shirt_test.png'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image.jpg\")\n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow(\"preview\")\n",
    "cv2.imshow(\"preview\", im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('/Users/denisdunn/Desktop/full_aerin/Aerin_Office_PhotoFrame_8x10.tif/Aerin_Office_PhotoFrame_8x10.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img('office_photoframe.jpg', img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
