{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/denisdunn/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D \n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'VERSION'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b8117435fd92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'VERSION'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating a CNN model with many VGG blocks\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "# function for creating a vgg block\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load an image from file\n",
    "import sys\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from numpy import expand_dims\n",
    "\n",
    "import pickle\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from numpy import expand_dims\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users/denisdunn/Desktop/full_aerin/fifty_plus_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory=os.listdir(\"/Users/denisdunn/Desktop/full_aerin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file=('/Users/denisdunn/Desktop/full_aerin/fifty_plus_class/{}').format(directory[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct=('/Users/denisdunn/Desktop/full_aerin/{}').format(directory[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#newPath = shutil.move(file, direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for files in directory:\n",
    "   # direct=('/Users/denisdunn/Desktop/full_aerin/{}').format(files)\n",
    "    #os.makedirs(direct)\n",
    "    #file=('/Users/denisdunn/Desktop/full_aerin/fifty_plus_class/{}').format(files)\n",
    "    #shutil.move(file, direct)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=('/Users/denisdunn/Desktop/full_aerin/F19_AERIN_NOAM_SET.tif/F19_AERIN_NOAM_SET.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/Users/denisdunn/Desktop/full_aerin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_img(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "/Users/denisdunn/Desktop/full_aerin/AERIN_IM_MOODBOARD_LR.jpg/AERIN_IM_MOODBOARD_LR.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for picture in directory:\n",
    "    try:\n",
    "        pic=('/Users/denisdunn/Desktop/full_aerin/{}/{}').format(picture,picture)\n",
    "        data=load_img(pic)\n",
    "        samples = expand_dims(data, 0)\n",
    "        saved=('/Users/denisdunn/Desktop/full_aerin/{}').format(picture)\n",
    "        it = datagen.flow(samples,batch_size=1,save_to_dir=saved)\n",
    "        for i in range(10):\n",
    "            batch = it.next()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=('/Users/denisdunn/Desktop/full_aerin/{}/{}').format('picture','picture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_img('/Users/denisdunn/Desktop/full_aerin/F19_AERIN_LIM_DIGITAL_1_HORIZ.jpg/F19_AERIN_LIM_DIGITAL_1_HORIZ.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = expand_dims(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=10,\n",
    "    height_shift_range=10,\n",
    "    #brightness_range=(.95,1.2),\n",
    "    channel_shift_range=20.0,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = datagen.flow(samples,batch_size=1,save_to_dir='/Users/denisdunn/Desktop/full_aerin/F19_AERIN_LIM_DIGITAL_1_HORIZ.jpg')\n",
    "#it = datagen.flow(samples,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# generate samples and plot\n",
    "for i in range(20):\n",
    "  # define subplot\n",
    "    #plt.subplot(330 + 1 + i)\n",
    "  # generate batch of images\n",
    "    batch = it.next()\n",
    "# convert to unsigned integers for viewing \n",
    "    #image = batch[0].astype('uint32')\n",
    "    \n",
    "# plot raw pixel data \n",
    "    #plt.imshow(image)\n",
    "# show the figure\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array_to_img(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "print(glob.glob(\"/Users/denisdunn/Desktop/full_aerin/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=os.listdir(\"/Users/denisdunn/Desktop/full_aerin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pics=os.listdir('/Users/denisdunn/Desktop/aerin_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pics.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR='/Users/denisdunn/Desktop/full_aerin'\n",
    "CATEGORIES=cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path =  os.path.join(DATADIR,category)\n",
    "for category in CATEGORIES:\n",
    "    path =  os.path.join(DATADIR,category)\n",
    "    class_num = CATEGORIES.index(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path =  os.path.join(DATADIR,category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                test_image = new_array[...,::-1]\n",
    "                training_data.append([test_image,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    "#cv2.IMREAD_GRAYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:   \n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "X=np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y,num_classes=44,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=cv2.imread('/Users/denisdunn/Desktop/shirt_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_img('/Users/denisdunn/Desktop/Screen Shot 2019-12-10 at 1.50.12 PM.png', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new model with random weights and 10 classes\n",
    "new_input = Input(shape=(224, 224, 3))\n",
    "model = VGG16( weights='imagenet',input_tensor=new_input, classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model.predict(image)\n",
    "decode_predictions(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "#model.fit(X,y,epochs=10,validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import load_model\n",
    "from keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1363/1363 [==============================] - 8s 6ms/step - loss: 3.7854 - accuracy: 0.0154\n",
      "Epoch 2/1000\n",
      "1363/1363 [==============================] - 8s 6ms/step - loss: 3.6881 - accuracy: 0.0345\n",
      "Epoch 3/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 3.4860 - accuracy: 0.0470\n",
      "Epoch 4/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 3.4243 - accuracy: 0.0433\n",
      "Epoch 5/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 3.3519 - accuracy: 0.0594\n",
      "Epoch 6/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 3.2545 - accuracy: 0.0712\n",
      "Epoch 7/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 3.0974 - accuracy: 0.0682\n",
      "Epoch 8/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.9482 - accuracy: 0.0726\n",
      "Epoch 9/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.7544 - accuracy: 0.1101\n",
      "Epoch 10/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.6544 - accuracy: 0.1240\n",
      "Epoch 11/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.5052 - accuracy: 0.1401\n",
      "Epoch 12/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 2.3556 - accuracy: 0.1717\n",
      "Epoch 13/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.3045 - accuracy: 0.2010\n",
      "Epoch 14/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.2117 - accuracy: 0.1966\n",
      "Epoch 15/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.1559 - accuracy: 0.2113\n",
      "Epoch 16/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 2.0642 - accuracy: 0.2450\n",
      "Epoch 17/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 2.0342 - accuracy: 0.2406\n",
      "Epoch 18/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.9579 - accuracy: 0.2494\n",
      "Epoch 19/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.8946 - accuracy: 0.2685\n",
      "Epoch 20/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.8189 - accuracy: 0.2847\n",
      "Epoch 21/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.7878 - accuracy: 0.3236\n",
      "Epoch 22/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.7316 - accuracy: 0.3331\n",
      "Epoch 23/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.7204 - accuracy: 0.3360\n",
      "Epoch 24/1000\n",
      "1363/1363 [==============================] - 9s 6ms/step - loss: 1.6320 - accuracy: 0.3756\n",
      "Epoch 25/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.5638 - accuracy: 0.3844\n",
      "Epoch 26/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.5319 - accuracy: 0.4043\n",
      "Epoch 27/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.4913 - accuracy: 0.4087\n",
      "Epoch 28/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.5103 - accuracy: 0.4263\n",
      "Epoch 29/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.4311 - accuracy: 0.4446\n",
      "Epoch 30/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.4008 - accuracy: 0.4512\n",
      "Epoch 31/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.3296 - accuracy: 0.4974\n",
      "Epoch 32/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.3140 - accuracy: 0.4989\n",
      "Epoch 33/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.3105 - accuracy: 0.4857\n",
      "Epoch 34/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.3039 - accuracy: 0.5172\n",
      "Epoch 35/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.2040 - accuracy: 0.5128\n",
      "Epoch 36/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.1563 - accuracy: 0.5415\n",
      "Epoch 37/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.1907 - accuracy: 0.5407\n",
      "Epoch 38/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.1522 - accuracy: 0.5422: 0s - loss: 1.1532 - accu\n",
      "Epoch 39/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.0896 - accuracy: 0.5767\n",
      "Epoch 40/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.0654 - accuracy: 0.5796\n",
      "Epoch 41/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.0383 - accuracy: 0.6067\n",
      "Epoch 42/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 1.0154 - accuracy: 0.6097\n",
      "Epoch 43/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 1.0435 - accuracy: 0.6016\n",
      "Epoch 44/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.9818 - accuracy: 0.6075\n",
      "Epoch 45/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.9444 - accuracy: 0.6412\n",
      "Epoch 46/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.9690 - accuracy: 0.6214\n",
      "Epoch 47/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.9516 - accuracy: 0.6442\n",
      "Epoch 48/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.9501 - accuracy: 0.6515\n",
      "Epoch 49/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.9392 - accuracy: 0.6434\n",
      "Epoch 50/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.8308 - accuracy: 0.6794\n",
      "Epoch 51/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.8118 - accuracy: 0.6941\n",
      "Epoch 52/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.8497 - accuracy: 0.6911\n",
      "Epoch 53/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.8647 - accuracy: 0.6787\n",
      "Epoch 54/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.8210 - accuracy: 0.6963\n",
      "Epoch 55/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.7753 - accuracy: 0.7190\n",
      "Epoch 56/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.7939 - accuracy: 0.7102\n",
      "Epoch 57/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.8765 - accuracy: 0.7073\n",
      "Epoch 58/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.7774 - accuracy: 0.7051\n",
      "Epoch 59/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.7369 - accuracy: 0.7366\n",
      "Epoch 60/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.7179 - accuracy: 0.7381\n",
      "Epoch 61/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.7519 - accuracy: 0.7395\n",
      "Epoch 62/1000\n",
      "1363/1363 [==============================] - 9s 6ms/step - loss: 0.7821 - accuracy: 0.7139\n",
      "Epoch 63/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.7216 - accuracy: 0.7329\n",
      "Epoch 64/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.6854 - accuracy: 0.7461\n",
      "Epoch 65/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.6673 - accuracy: 0.7594\n",
      "Epoch 66/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.7317 - accuracy: 0.7410\n",
      "Epoch 67/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.6677 - accuracy: 0.7506\n",
      "Epoch 68/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.6507 - accuracy: 0.7762\n",
      "Epoch 69/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.7110 - accuracy: 0.7674\n",
      "Epoch 70/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.6705 - accuracy: 0.7594\n",
      "Epoch 71/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.6321 - accuracy: 0.7740\n",
      "Epoch 72/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.5987 - accuracy: 0.7865\n",
      "Epoch 73/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.5966 - accuracy: 0.7850\n",
      "Epoch 74/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.5344 - accuracy: 0.7982\n",
      "Epoch 75/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.5714 - accuracy: 0.7887\n",
      "Epoch 76/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.5672 - accuracy: 0.7880\n",
      "Epoch 77/1000\n",
      "1363/1363 [==============================] - 10s 7ms/step - loss: 0.5900 - accuracy: 0.7836\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.6544 - accuracy: 0.7755\n",
      "Epoch 79/1000\n",
      "1363/1363 [==============================] - 9s 7ms/step - loss: 0.5651 - accuracy: 0.7909\n",
      "Epoch 00079: early stopping\n",
      "1363/1363 [==============================] - 0s 183us/step\n",
      "Test accuracy: 0.8173147439956665\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\",input_shape=(10,10,1)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(224, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    #keras.layers.Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(.5),\n",
    "    #keras.layers.Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(28, activation='relu'),\n",
    "    keras.layers.Dropout(.1),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    \n",
    "    keras.layers.Dense(44, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "es=EarlyStopping(patience=5, monitor='loss',verbose=1)\n",
    "\n",
    "model.fit(X, y, epochs=1000, batch_size=5,callbacks=[es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X, y)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pic='/Users/denisdunn/Desktop/aerin_test/{}'.format(test_pics[6])\n",
    "len(test_pics)\n",
    "import time\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('11_of_28.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-414-bade964d7a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#pic='/Users/denisdunn/Desktop/aerin_test/Screen Shot 2020-02-11 at 12.18.09 PM.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/denisdunn/Desktop/aerin_test/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpic_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/denisdunn/opt/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \"\"\"\n\u001b[1;32m    699\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PNG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"eXIf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#pic='/Users/denisdunn/Desktop/aerin_test/Screen Shot 2020-02-11 at 12.18.09 PM.png'\n",
    "pic='/Users/denisdunn/Desktop/aerin_test/{}'.format(test_pics[8])\n",
    "pic_test(pic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(test):\n",
    "    #array_test=img_to_array(test)\n",
    "    array_resize=cv2.resize(test,(IMG_SIZE,IMG_SIZE))\n",
    "    return (np.array(array_resize).reshape(1,IMG_SIZE,IMG_SIZE,1))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "denis=cv2.imread('/Users/denisdunn/Desktop/Screen Shot 2020-01-29 at 2.56.19 PM.png',cv2.IMREAD_GRAYSCALE)\n",
    "#cv2.IMREAD_GRAYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prob = model.predict(answer).flatten()\n",
    "top_values_index = sorted(range(len(class_prob)), key=lambda i: class_prob[i])[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 4,\n",
       " 9,\n",
       " 31,\n",
       " 20,\n",
       " 32,\n",
       " 41,\n",
       " 24,\n",
       " 16,\n",
       " 1,\n",
       " 18,\n",
       " 13,\n",
       " 28,\n",
       " 25,\n",
       " 8,\n",
       " 7,\n",
       " 22,\n",
       " 30,\n",
       " 38,\n",
       " 26,\n",
       " 33,\n",
       " 27,\n",
       " 40,\n",
       " 37,\n",
       " 6,\n",
       " 19,\n",
       " 34,\n",
       " 17,\n",
       " 21,\n",
       " 2,\n",
       " 39,\n",
       " 35,\n",
       " 11,\n",
       " 3,\n",
       " 43,\n",
       " 0,\n",
       " 14,\n",
       " 12,\n",
       " 5,\n",
       " 23,\n",
       " 42,\n",
       " 10,\n",
       " 36,\n",
       " 29]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_image(CATEGORIES[top_values_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SP17_AERIN_DOR_HERO_1.jpg'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=image_processing(denis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S20_AERIN_WG_DIGITAL_SQUARE_11.jpg\n"
     ]
    }
   ],
   "source": [
    "result=model.predict_classes(answer)\n",
    "print(CATEGORIES[int(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6779360e-03, 2.8093849e-13, 3.9898109e-06, 8.5570301e-15,\n",
       "       1.9124144e-08, 3.0494949e-09, 1.3197686e-05, 8.6762710e-17,\n",
       "       3.8851532e-26, 2.2551899e-15, 9.7172573e-02, 1.3802902e-12,\n",
       "       2.8197104e-04, 1.7033757e-05, 2.1874039e-06, 2.1235908e-27,\n",
       "       7.7401595e-16, 1.1711552e-09, 6.8640402e-26, 6.1201408e-06,\n",
       "       1.3556033e-04, 8.5409480e-01, 6.8692435e-10, 4.0883165e-02,\n",
       "       1.1159374e-03, 8.2113518e-04, 4.3550582e-04, 1.0376082e-08,\n",
       "       8.9226525e-14, 8.0570571e-06, 4.0355204e-16, 3.4637216e-19,\n",
       "       5.8150299e-16, 5.6496909e-09, 2.0577718e-16, 4.2428530e-04,\n",
       "       3.2172816e-06, 9.7216858e-14, 2.5099700e-15, 3.3749972e-11,\n",
       "       2.5125715e-07, 9.0308295e-04, 1.4658516e-08, 4.6348359e-24],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict(answer) \n",
    "max(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.6119512e-05, 9.5760463e-15, 1.3716018e-05, 3.2071839e-14,\n",
       "        1.9450461e-08, 9.4613881e-09, 1.6584640e-09, 8.2424371e-18,\n",
       "        7.7262789e-22, 6.0804253e-13, 7.8762257e-01, 3.2652206e-08,\n",
       "        5.2552402e-04, 8.3106925e-04, 3.0633262e-05, 3.0159240e-25,\n",
       "        3.8762491e-13, 1.3903785e-10, 6.3360107e-19, 3.4574492e-05,\n",
       "        5.0604181e-06, 2.3580598e-02, 1.4521406e-14, 1.7698675e-01,\n",
       "        2.1003647e-04, 1.3935368e-04, 7.0902862e-04, 6.4197168e-11,\n",
       "        5.9437916e-08, 5.2651425e-04, 2.2700809e-15, 2.8366718e-16,\n",
       "        2.8832530e-18, 1.3610212e-07, 8.6150726e-16, 8.6445110e-03,\n",
       "        2.6318496e-05, 1.8588560e-12, 8.2855442e-15, 6.1687651e-08,\n",
       "        2.9364492e-07, 1.3107026e-05, 2.3904056e-05, 2.8601812e-19]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(answer)\n",
    "y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic='/Users/denisdunn/Desktop/HOL19_AERIN_ MODEL_F72.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pic_test(pic):\n",
    "    denis=cv2.imread(pic,cv2.IMREAD_GRAYSCALE)\n",
    "    answer=image_processing(denis)\n",
    "    result=model.predict_classes(answer)\n",
    "    direct='/Users/denisdunn/Desktop/full_aerin/{}/{}'.format(CATEGORIES[int(result)],CATEGORIES[int(result)])\n",
    "    return load_img(direct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct='/Users/denisdunn/Desktop/full_aerin/{}/{}'.format(CATEGORIES[int(result)],CATEGORIES[int(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_test('/Users/denisdunn/Desktop/_0_117.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('feb_5_size_25_batch5_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/denisdunn/Desktop/DATADIR/X',X)\n",
    "np.save('/Users/denisdunn/Desktop/DATADIR/y',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Conv2D(input_shape=(50,50,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
    "keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
    "keras.layers.Flatten(),\n",
    "keras.layers.Dense(units=4096,activation=\"relu\"),\n",
    "keras.layers.Dense(units=4096,activation=\"relu\"),\n",
    "keras.layers.Dense(units=44, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "es=EarlyStopping(patience=20, monitor='acc',verbose=1)\n",
    "model.fit(X, y, epochs=1000, batch_size=10,callbacks=[es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X, y)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "from six.moves import range\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out any prior log data.\n",
    "!rm -rf logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/train_data/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the reshaped image.\n",
    "with file_writer.as_default():\n",
    "  tf.summary.image(\"Training data\", img, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2,time\n",
    "import numpy as np\n",
    "print(cv2.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('file:///Users/denisdunn/opt/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.imread('/Users/denisdunn/Desktop/Ivb19_0881-319x319.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=face_cascade.detectMultiScale(gray,scaleFactor=1.05,minNeighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,w,h, in faces:\n",
    "    img = cv2.rectangle(gray, (x,y), (x+w,y+h),(0,255,0),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('gray',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "\n",
    "#cvim2disp = cv2.imread('/Users/denisdunn/Desktop/Ivb19_0881-319x319.png')\n",
    "cv2.imshow('img', img)\n",
    "while(True):\n",
    "    k = cv2.waitKey(33)\n",
    "    if k == -1:  # if no key was pressed, -1 is returned\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyWindow('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=cv2.VideoCapture(0)\n",
    "check,frame=video.read()\n",
    "time.sleep(3) \n",
    "cv2.imshow('Capture',frame)\n",
    "cv2.waitKey(0)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyWindow('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/denisdunn/Desktop/shirt_test.png'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "while(True):\n",
    "    k = cv2.waitKey(33)\n",
    "    if k == -1:  # if no key was pressed, -1 is returned\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyWindow('img')\n",
    "#if cv2.waitKey(0) & 0xff == 27:\n",
    "    #cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/denisdunn/Desktop/shirt_test.png'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image.jpg\")\n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow(\"preview\")\n",
    "cv2.imshow(\"preview\", im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('/Users/denisdunn/Desktop/full_aerin/Aerin_Office_PhotoFrame_8x10.tif/Aerin_Office_PhotoFrame_8x10.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img('office_photoframe.jpg', img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
