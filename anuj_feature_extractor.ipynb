{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dedunn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, argparse\n",
    "import pickle\n",
    "import cv2, numpy as np\n",
    "#from keras.models import model_from_json\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.externals import joblib\n",
    "from tensorflow.keras import backend as K\n",
    "#import keras\n",
    "from tensorflow.keras.models import load_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dedunn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\dedunn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\dedunn\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# File paths for the model, all of these except the CNN Weights are \n",
    "# provided in the repo, See the VGG_model/README.md to download VGG weights\n",
    "#CNN_weights_file_name   = 'imagenet'\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "model=load_model(r\"C:\\Users\\dedunn\\Desktop\\unique_path_summary_model.h5\")\n",
    "# Chagne the value of verbose to 0 to avoid printing the progress statements\n",
    "verbose = 1\n",
    "\n",
    "def get_image_model(CNN_weights_file_name):\n",
    "    ''' Takes the CNN weights file, and returns the VGG model update \n",
    "    with the weights. Requires the file VGG.py inside models/CNN '''\n",
    "    #from VGG_model.VGG import VGG_16\n",
    "    image_model = VGG16(CNN_weights_file_name)\n",
    "\n",
    "    # this is standard VGG 16 without the last two layers\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # one may experiment with \"adam\" optimizer, but the loss function for\n",
    "    # this kind of task is pretty standard\n",
    "    image_model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    return image_model\n",
    "\n",
    "#vgg16_model = get_image_model(CNN_weights_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_4 (Model)              (None, 220, 220, 32)      2688      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 108, 108, 32)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64800)             0         \n",
      "=================================================================\n",
      "Total params: 2,688\n",
      "Trainable params: 2,560\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(model):\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # one may experiment with \"adam\" optimizer, but the loss function for\n",
    "    # this kind of task is pretty standard\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=custom_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(image_file_name):\n",
    "    ''' Runs the given image_file to VGG 16 model and returns the \n",
    "    weights (filters) as a 1, 4096 dimension vector '''\n",
    "    image_features = np.zeros((1, 64800))\n",
    "    # Magic_Number = 4096  > Comes from last layer of VGG Model\n",
    "\n",
    "    # Since VGG was trained as a image of 224x224, every new image\n",
    "    # is required to go through the same transformation\n",
    "    im = cv2.resize(cv2.imread(image_file_name), (224, 224))\n",
    "\n",
    "\n",
    "    # The mean pixel values are taken from the VGG authors, which are the values computed from the training dataset.\n",
    "    mean_pixel = [103.939, 116.779, 123.68]\n",
    "\n",
    "    im = im.astype(np.float32, copy=False) # shape of im = (224,224,3)\n",
    "    \n",
    "    for c in range(3):\n",
    "        im[:, :, c] = im[:, :, c] - mean_pixel[c]        \n",
    "\n",
    "    #im = im.transpose((2,0,1)) # convert the image to RGBA  # shame of im= (3,224,224)\n",
    "\n",
    "    \n",
    "    # this axis dimension is required becuase VGG was trained on a dimension\n",
    "    # of 1, 3, 224, 224 (first axis is for the batch size\n",
    "    # even though we are using only one image, we have to keep the dimensions consistent\n",
    "    im = np.expand_dims(im, axis=0)  # shape of im = (1,3,224,224)\n",
    "\n",
    "    image_features[0,:] = model.predict(im)[0]\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=os.getcwd()\n",
    "#data_path = PATH + '/every_aerin'\n",
    "data_path=r\"C:\\Users\\dedunn\\Desktop\\every_aerin\"\n",
    "#\"C:\\Users\\dedunn\\Desktop\\every_aerin\"\n",
    "data_dir_list = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_list[0]\n",
    "#\"C:\\Users\\dedunn\\Desktop\\every_aerin\\19_AERINxJO_DIGITAL_1.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    data_path=r\"C:\\Users\\dedunn\\Desktop\\every_aerin\\{}\".format(dataset)\n",
    "    #img_list=os.listdir(data_path)\n",
    "    #print ('Extracting Features of dataset-'+'{}\\n'.format(dataset))\n",
    "    #for img in img_list:\n",
    "    try:\n",
    "        image_features=get_image_features(data_path)\n",
    "        image_features_list.append(image_features)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "image_features_arr=np.asarray(image_features_list)\n",
    "image_features_arr = np.rollaxis(image_features_arr,1,0)\n",
    "image_features_arr = image_features_arr[0,:,:]\n",
    "\n",
    "np.savetxt('feature_vectors_denis_samples.txt',image_features_arr)\n",
    "#feature_vectors = np.loadtxt('feature_vectors.txt')\n",
    "pickle.dump(image_features_arr, open('feature_vectors_denis_samples.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
